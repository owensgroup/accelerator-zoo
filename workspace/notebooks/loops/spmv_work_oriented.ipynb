{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fa06aa",
   "metadata": {},
   "source": [
    "# TeAAL specifications on variants of Loops' SpMV implementations (Work Oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840ee46",
   "metadata": {},
   "source": [
    "Description: All threads are assigned (`TOTAL_WORK` / `Number of Processors`) work items. Each thread then sequentially processes assigned work items in a loop. `TOTAL_WORK` = `NNZ` + `NUM_ROWS`.\n",
    "\n",
    "During the Setup phase, the number of work units per thread is computed, and 2-D binary search within the nonzero indices and row offsets of a CSR matrix is conducted to get the starting position of each tile and atom in a thread-local variable. In the next phase, the algorithm builds the ranges for each thread to process as \"complete\" tiles and \"partial\" tiles. If a thread's atom range lies entirely within one tile, it is \"complete\", and is processed in a simple nested loop. If a thread's range crosses a tile boundary, the thread processes its work in a separate nested loop.\n",
    "\n",
    "Template: https://github.com/gunrock/loops/blob/main/include/loops/algorithms/spmv/work_oriented.cuh\n",
    "\n",
    "Scheduler (referenced as `config` below): https://github.com/gunrock/loops/blob/main/include/loops/schedule/work_oriented.hxx\n",
    "\n",
    "GPU Kernel Template (Use it as a reference, don't execute it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55b95f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "template <std::size_t threads_per_block,\n",
    "          typename index_t,\n",
    "          typename offset_t,\n",
    "          typename type_t>\n",
    "__global__ void __launch_bounds__(threads_per_block, 2)\n",
    "    __work_oriented(std::size_t rows,\n",
    "                    std::size_t cols,\n",
    "                    std::size_t nnz,\n",
    "                    offset_t* offsets,\n",
    "                    index_t* indices,\n",
    "                    const type_t* values,\n",
    "                    const type_t* x,\n",
    "                    type_t* y) {\n",
    "  using setup_t =\n",
    "      schedule::setup<schedule::algorithms_t::work_oriented, threads_per_block,\n",
    "                      1, index_t, offset_t, std::size_t, std::size_t>;\n",
    "\n",
    "  setup_t config(offsets, rows, nnz);\n",
    "  auto map = config.init();\n",
    "\n",
    "  /// Accumulate the complete tiles.\n",
    "  type_t sum = 0;\n",
    "  for (auto row : config.tiles(map)) {\n",
    "    for (auto nz : config.atoms(row, map)) {\n",
    "      sum += values[nz] * x[indices[nz]];\n",
    "    }\n",
    "    y[row] = sum;\n",
    "    sum = 0;\n",
    "  }\n",
    "\n",
    "  // Interesting use of syncthreads to ensure all remaining tiles get processed\n",
    "  // at the same time, possibly causing less thread divergence among the threads\n",
    "  // in the same warp.\n",
    "  __syncthreads();\n",
    "\n",
    "  /// Process remaining tiles.\n",
    "  for (auto row : config.remainder_tiles(map)) {\n",
    "    for (auto nz : config.remainder_atoms(map)) {\n",
    "      sum += values[nz] * x[indices[nz]];\n",
    "    }\n",
    "    /// Accumulate the remainder.\n",
    "    if (sum != 0)\n",
    "      atomicAdd(&(y[row]), sum);\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426ccd4-8cb8-4c26-8749-1fb6e2a3aa2b",
   "metadata": {},
   "source": [
    "## 2-D Binary Search (Not being used in TeAAL Specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eb475-d683-485e-b004-5ef3e60d802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(row_offsets, values, NUM_THREADS_PER_CYCLE, TOTAL_WORK, WORK_PER_THREAD):\n",
    "    ranges = []\n",
    "    for tid in range(NUM_THREADS_PER_CYCLE):\n",
    "        upper = min((WORK_PER_THREAD * tid), TOTAL_WORK)\n",
    "        lower = min((upper + WORK_PER_THREAD), TOTAL_WORK)\n",
    "\n",
    "        st = search(upper, row_offsets[1:], values);\n",
    "        en = search(lower, row_offsets[1:], values);\n",
    "        ranges.append((st, en))\n",
    "    return ranges\n",
    "\n",
    "def search(diagonal, row_offsets, values):\n",
    "    low = max((diagonal - len(values)), 0)\n",
    "    high = min(diagonal, len(row_offsets))\n",
    "\n",
    "    # binary search\n",
    "    while low < high:\n",
    "        mid = (low + high) // 2\n",
    "        if row_offsets[mid] <= values[diagonal - mid - 1]:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    return (min(low, len(row_offsets)), diagonal - low)\n",
    "\n",
    "# Get CSR row offsets of A\n",
    "A_NNZ = 0\n",
    "row_offsets = [0]\n",
    "values = []\n",
    "\n",
    "row_it = iter(A_IJ.getRoot().getCoords())\n",
    "val_it = iter(A_IJ.getRoot().getPayloads())\n",
    "prev_row = next(row_it)\n",
    "\n",
    "for row_id in range(I):\n",
    "    if prev_row is not None:\n",
    "        cur_row = prev_row\n",
    "        if row_id == cur_row: # Check if empty row\n",
    "            for nz in next(val_it).getPayloads():\n",
    "                values.append(nz.v())\n",
    "                A_NNZ += 1\n",
    "            prev_row = next(row_it, None) # Returns None if iterator is done\n",
    "    row_offsets.append(A_NNZ)\n",
    "\n",
    "print(\"A row offsets:\", row_offsets)\n",
    "print(\"A values:\", values)\n",
    "print(f\"A_NNZ: {A_NNZ}\")\n",
    "\n",
    "TOTAL_WORK = A_NNZ + I\n",
    "WORK_PER_THREAD = math.ceil(TOTAL_WORK / NUM_THREADS_PER_CYCLE)\n",
    "print(f\"TOTAL_WORK: {TOTAL_WORK}, WORK_PER_THREAD = {WORK_PER_THREAD}\")\n",
    "\n",
    "# Get range for each tid\n",
    "ranges = setup(row_offsets, values, NUM_THREADS_PER_CYCLE, TOTAL_WORK, WORK_PER_THREAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2986d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b113dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a14b2",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the input tensors.\n",
    "\n",
    "For simplicity, suppose that each GPU SM processes 1 thread warp/block with size `BLOCK_SIZE` per cycle.\n",
    "\n",
    "Things that are different from the actual implementation of the work-oriented method:\n",
    "- Skipping the 2-D binary search to find the range of tiles. Therefore, `TOTAL_WORK` is simply equal to `A_NNZ`.\n",
    "- Skipping the part of processing \"complete\" and \"partial\" tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 4\n",
    "J = 4\n",
    "\n",
    "NUM_SM = 2 # Number of GPU SMs \n",
    "BLOCK_SIZE = 2 # Number of threads per block \n",
    "NUM_THREADS_PER_CYCLE = BLOCK_SIZE * NUM_SM # Total number of threads processed per cycle\n",
    "\n",
    "print(f\"NUM_SM: {NUM_SM}, BLOCK_SIZE: {BLOCK_SIZE}, NUM_THREADS_PER_CYCLE: {NUM_THREADS_PER_CYCLE}\")\n",
    "seed = 1\n",
    "\n",
    "A_IJ = Tensor.fromRandom(rank_ids=[\"I\", \"J\"], shape=[I, J], seed=seed, density=[0.9, 0.6], name=\"A\")\n",
    "B_J = Tensor.fromRandom(rank_ids=[\"J\"], shape=[J], seed=seed + 1, density=[1], name=\"B\")\n",
    "\n",
    "# Get A_NNZ\n",
    "A_NNZ = 0\n",
    "\n",
    "for row in A_IJ.getRoot().getPayloads():\n",
    "    for nz in row.getPayloads():\n",
    "        A_NNZ += 1\n",
    "\n",
    "print(f\"A_NNZ: {A_NNZ}\")\n",
    "\n",
    "TOTAL_WORK = A_NNZ\n",
    "WORK_PER_THREAD = math.ceil(TOTAL_WORK / NUM_THREADS_PER_CYCLE)\n",
    "print(f\"TOTAL_WORK: {TOTAL_WORK}, WORK_PER_THREAD = {WORK_PER_THREAD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1afb77",
   "metadata": {},
   "source": [
    "TeAAL Specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "  declaration:\n",
    "    A: [I, J]\n",
    "    B: [J]\n",
    "    Z: [I]\n",
    "  expressions:\n",
    "    - Z[i] = A[i, j] * B[j]\n",
    "mapping:\n",
    "  rank-order:\n",
    "    A: [I, J]\n",
    "    B: [J]\n",
    "    Z: [I]\n",
    "  partitioning:\n",
    "    Z:\n",
    "      (I, J): [flatten()]\n",
    "      IJ: [uniform_occupancy(A.WORK_PER_THREAD)]\n",
    "  loop-order:\n",
    "    Z: [IJ1, IJ0]\n",
    "  spacetime:\n",
    "    Z:\n",
    "      space: [IJ1]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c0d",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "\n",
    "Check that generated code computes the correct result.\n",
    "\n",
    "**Note**: Should be used after compiling and running the kernel (above cell).\n",
    "\n",
    "**Disclaimer**: The values for `Z_I` shown in the animation may be different from the actual values of `Z_I`. Run the command below to confirm if `Z_I` has been computed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matrix_vector_mul(A_IJ, B_J, Z_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd1e9f-fdb5-46c7-ad00-a0164b854d1b",
   "metadata": {},
   "source": [
    "## Performance on GPU\n",
    "\n",
    "Load Balance: Nearly-perfect load balance across the threads. Threads are assigned to an equal number of work items. \n",
    "\n",
    "Assuming that the $A$ is stored in CSR format, $B$ and $Z$ are in uncompressed vectors, the memory access pattern would be:\n",
    "- A: Uncoalesced access when threads are accessing complete tiles. There is an opportunity for coalesced access for partial tiles, but it is not guaranteed.\n",
    "- B: Depends on the column indices of each nonzero entry of $A$. The more irregular the sparsity pattern that $A$ has, the more random the column indices of $A$'s nonzero entries will be. This should result in more uncoalesced accesses to $B$.\n",
    "- Z: Same as $A$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
