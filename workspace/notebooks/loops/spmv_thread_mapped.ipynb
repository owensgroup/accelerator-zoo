{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fa06aa",
   "metadata": {},
   "source": [
    "# TeAAL specifications on variants of Loops' SpMV implementations (Thread-Mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840ee46",
   "metadata": {},
   "source": [
    "Description: Assign a fixed, constant number of work tiles to each thread. Resultant work items from each work tile are processed sequentially within the thread. \n",
    "\n",
    "In this version, each `tile` represents a row of $A$, and each `atom` represents a nonzero entry of $A$. In other words, assigning a thread to each row of $A$. Therefore, TeAAL specs is idential to the original.\n",
    "\n",
    "Template: https://github.com/gunrock/loops/blob/main/include/loops/algorithms/spmv/thread_mapped.cuh\n",
    "\n",
    "Scheduler (referenced as `config` below): https://github.com/gunrock/loops/blob/main/include/loops/schedule/thread_mapped.hxx\n",
    "\n",
    "GPU Kernel Template (Use it as a reference, don't execute it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55b95f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "template <typename setup_t,\n",
    "          typename index_t,\n",
    "          typename offset_t,\n",
    "          typename type_t>\n",
    "__global__ void __thread_mapped(setup_t config,\n",
    "                                const std::size_t rows,\n",
    "                                const std::size_t cols,\n",
    "                                const std::size_t nnz,\n",
    "                                const offset_t* offsets,\n",
    "                                const index_t* indices,\n",
    "                                const type_t* values,\n",
    "                                const type_t* x,\n",
    "                                type_t* y) {\n",
    "  /// Equivalent to:\n",
    "  /// row = blockIdx.x * blockDim.x + threadIdx.x; (init)\n",
    "  /// row < rows; (boundary condition)\n",
    "  /// row += gridDim.x * blockDim.x. (step)\n",
    "  for (auto row : config.tiles()) {\n",
    "    type_t sum = 0;\n",
    "\n",
    "    /// Equivalent to:\n",
    "    /// for (offset_t nz = offset; nz < end; ++nz)\n",
    "    for (auto nz : config.atoms(row)) {\n",
    "      sum += values[nz] * x[indices[nz]];\n",
    "    }\n",
    "\n",
    "    // Output\n",
    "    y[row] = sum;\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2986d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b113dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a14b2",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the input tensors.\n",
    "\n",
    "For simplicity, suppose that each GPU SM processes 1 thread warp/block with size `BLOCK_SIZE` per cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 8\n",
    "J = 8\n",
    "\n",
    "NUM_SM = 2 # Number of GPU SMs \n",
    "BLOCK_SIZE = 2 # Number of threads per block \n",
    "NUM_THREADS_PER_CYCLE = BLOCK_SIZE * NUM_SM # Total number of threads processed per cycle\n",
    "\n",
    "print(f\"NUM_SM: {NUM_SM}, BLOCK_SIZE: {BLOCK_SIZE}, NUM_THREADS_PER_CYCLE: {NUM_THREADS_PER_CYCLE}\")\n",
    "seed = 1\n",
    "\n",
    "A_IJ = Tensor.fromRandom(rank_ids=[\"I\", \"J\"], shape=[I, J], seed=seed, density=[0.9, 0.6], name=\"A\")\n",
    "B_J = Tensor.fromRandom(rank_ids=[\"J\"], shape=[J], seed=seed + 1, density=[1], name=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1afb77",
   "metadata": {},
   "source": [
    "TeAAL Specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "  declaration:\n",
    "    A: [I, J]\n",
    "    B: [J]\n",
    "    Z: [I]\n",
    "  expressions:\n",
    "    - Z[i] = A[i, j] * B[j]\n",
    "mapping:\n",
    "  rank-order:\n",
    "    A: [I, J]\n",
    "    B: [J]\n",
    "    Z: [I]\n",
    "  partitioning:\n",
    "    Z:\n",
    "      I: [uniform_shape(NUM_THREADS_PER_CYCLE)]\n",
    "  loop-order:\n",
    "    Z: [I1, I0, J]\n",
    "  spacetime:\n",
    "    Z:\n",
    "      space: [I0]\n",
    "      time: [I1, J]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c0d",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "\n",
    "Check that generated code computes the correct result.\n",
    "\n",
    "**Note**: Should be used after compiling and running the kernel (above cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matrix_vector_mul(A_IJ, B_J, Z_I)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
