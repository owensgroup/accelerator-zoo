{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fa06aa",
   "metadata": {},
   "source": [
    "# TeAAL specifications on variants of Loops' SpGEMM implementations (Thread-Mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840ee46",
   "metadata": {},
   "source": [
    "Description: Assign a fixed, constant number of work tiles to each thread. Resultant work items from each work tile are processed sequentially within the thread. \n",
    "\n",
    "In this version, each `tile` represents a row of $A$, and each `atom` represents a nonzero entry of $A$. In other words, assigning a thread to each row of $A$. For SpGEMM, following Gustavson's row-row dataflow (multiply a row of A and a row of B to get a partial row of Z, then merge the partial rows) as instructed in [A Programming Model for GPU Load Balancing](https://arxiv.org/abs/2301.04792)\n",
    "\n",
    "Template: DNE in Loops\n",
    "\n",
    "Scheduler (referenced as `config` below): https://github.com/gunrock/loops/blob/main/include/loops/schedule/thread_mapped.hxx\n",
    "\n",
    "GPU Kernel Template (Use it as a reference, don't execute it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55b95f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [],
   "source": [
    "__global__ void __thread_mapped(...) {\n",
    "  for (auto A_row : config.tiles()) { # Loop over assigned rows for each tid.\n",
    "    for (auto A_nz_idx : config.atoms(A_row)) { # Loop over nonzero entry of current row of A, let its col index = j\n",
    "      for (auto B_nz_idx : get_B_nz(get_A_col(A_nz_idx))) { # Loop over nonzero entry of j-th row of B and multiply\n",
    "        B_col = get_B_col(B_nz_idx);\n",
    "        Z(A_row, B_col) += A_values[A_nz_idx] * B_values[B_nz_idx];\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2986d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b113dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a14b2",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the input tensors.\n",
    "\n",
    "For simplicity, the size of a thread warp is the same as the size of a thread block (`WARP_SIZE = BLOCK_SIZE`). Suppose that each GPU SM processes 1 thread warp/block per cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "M = 4\n",
    "N = 4\n",
    "\n",
    "# GPU Kernel Configuration\n",
    "BLOCK_SIZE = 2 # Number of threads per block\n",
    "GRID_SIZE = (M + BLOCK_SIZE - 1) // BLOCK_SIZE # Number of thread blocks\n",
    "\n",
    "print(f\"GPU Kernel Configuration\\n \\\n",
    "        BLOCK_SIZE (Number of threads per block): {BLOCK_SIZE} \\n \\\n",
    "        GRID_SIZE (Number of thread blocks): {GRID_SIZE}\")\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# SpGEMM, both A and B are sparse\n",
    "A_MK = Tensor.fromRandom(rank_ids=[\"M\", \"K\"], shape=[M, K], seed=seed, density=[0.9, 0.6], name=\"A\")\n",
    "#A_MK = Tensor.fromUncompressed(rank_ids=[\"M\", \"K\"], root=[[0,0,8,0],[4,1,0,10],[0,4,2,0],[9,7,0,0]], shape=[M, K], name=\"A\")\n",
    "B_KN = Tensor.fromRandom(rank_ids=[\"K\", \"N\"], shape=[K, N], seed=seed, density=[0.9, 0.6], name=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1afb77",
   "metadata": {},
   "source": [
    "## TeAAL Specifications\n",
    "\n",
    "Rows of matrix $A$ are partitioned across the SMs' threads. A thread can be assigned to a row with all zeros. \n",
    "\n",
    "Note that the current TeAAL specificaiton does not allow to specify the rank of `opt: slip`. This means there exists a synchronization across the SMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "  declaration:\n",
    "    A: [M, K]\n",
    "    B: [K, N]\n",
    "    T: [K, M, N]\n",
    "    Z: [M, N]\n",
    "  expressions:\n",
    "    - T[k, m, n] = A[m, k] * B[k, n]\n",
    "    - Z[m, n] = T[k, m, n]\n",
    "mapping:\n",
    "  rank-order:\n",
    "    A: [M, K]\n",
    "    B: [K, N]\n",
    "    T: [K, M, N]\n",
    "    Z: [M, N]\n",
    "  partitioning:\n",
    "    T:\n",
    "      M: [uniform_shape(BLOCK_SIZE)]\n",
    "    Z:\n",
    "      M: [uniform_shape(BLOCK_SIZE)]\n",
    "  loop-order:\n",
    "    T: [M1, M0, K, N]\n",
    "    Z: [M1, M0, K, N]\n",
    "    # M1: Number of partitioned rows of A = GRID_SIZE = Number of thread blocks\n",
    "    # M0: Size of each partitioned row of A = BLOCK_SIZE\n",
    "  spacetime:\n",
    "    T:\n",
    "      space: [M1, M0]\n",
    "      time: [K, N] \n",
    "    Z:\n",
    "      space: [M1, M0]\n",
    "      time: [K, N] \n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c0d",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "\n",
    "Check that generated code computes the correct result.\n",
    "\n",
    "**Note**: Should be used after compiling and running the kernel (above cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matmul(A_MK, B_KN, Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feccd38-93e7-444c-afa7-b43f0b4d1bb1",
   "metadata": {},
   "source": [
    "## Performance on GPU\n",
    "\n",
    "Load Balance: Poor load balance due to the difference in NNZ per row of $A$. This results in threads that are assigned to rows with few NNZ being idle.\n",
    "\n",
    "Assuming that the $A$, $B$, and $Z$ are stored in CSR format, the memory access pattern would be:\n",
    "- A: Uncoalesced access, threads in a warp are accessing different rows of $A$.\n",
    "- B: Uncoalesced access, threads in a warp are accessing rows of $B$ based on column indices of $A$'s nonzero entries.\n",
    "- Z: Uncoalesced access, threads in a warp are writing to different rows of $Z$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
